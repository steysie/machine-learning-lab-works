{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная 1 - Вариант 1\n",
    "Мухина Елена и Никифорова Анастасия\n",
    "\n",
    "10/05/2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Описание данных:**\n",
    "\n",
    "Набор данных NASA содержит информацию о аэродинамических поверхностях NACA 0012 различного размера при различных скоростях аэродинамической трубы и углах атаки. Пролет аэродинамической поверхности и положения наблюдателя были одинаковы во всех экспериментах.\n",
    "\n",
    "**Информация об атрибутах:**\n",
    "\n",
    "Данная задача на входе принимает 5 атрибутов: \n",
    "1. Частота, в Гц. \n",
    "2. Угол атаки, в градусах. \n",
    "3. Длина хорды, в метрах. \n",
    "4. Скорость свободного потока, в метрах в секунду. \n",
    "5. Толщина всасывания бокового смещения, в метрах. \n",
    "\n",
    "На выходе получаем один атрибут: \n",
    "6. Измеренный уровень звукового давления, в децибелах. \n",
    "\n",
    "**Задача:** Мы хотим на основании признаков 1-5 предсказать уровень звукового давления (Scaled sound pressure level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "# В качестве параметра передаем имя файла и разделитель - символ, которым проводится разбиение данных в файле\n",
    "inputData = pd.read_csv('airfoil1.csv', delimiter='\\t')\n",
    "#inputData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Angle of Attack</th>\n",
       "      <th>Chord Length</th>\n",
       "      <th>Free-Steam Velocity</th>\n",
       "      <th>Suction side displacement thickness</th>\n",
       "      <th>Scaled sound pressure level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.661802</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>-0.644590</td>\n",
       "      <td>0.197873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.598362</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>-0.644590</td>\n",
       "      <td>0.052917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.519062</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>-0.644590</td>\n",
       "      <td>0.161634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.408041</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>-0.644590</td>\n",
       "      <td>0.399361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.281161</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>-0.644590</td>\n",
       "      <td>0.380517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.122560</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>-0.644590</td>\n",
       "      <td>0.106551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.083620</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>-0.644590</td>\n",
       "      <td>0.052917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.353241</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>-0.644590</td>\n",
       "      <td>-0.257288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.670443</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>-0.644590</td>\n",
       "      <td>-0.512410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.082804</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>-0.644590</td>\n",
       "      <td>-0.767532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.622046</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>-0.644590</td>\n",
       "      <td>-1.113977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.256449</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>-0.644590</td>\n",
       "      <td>-1.369099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.049452</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>-0.644590</td>\n",
       "      <td>-1.825709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.159656</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>-0.644590</td>\n",
       "      <td>-2.335954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.756963</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>0.297908</td>\n",
       "      <td>-0.631857</td>\n",
       "      <td>0.229038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.715727</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>0.297908</td>\n",
       "      <td>-0.631857</td>\n",
       "      <td>0.414582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.661802</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>0.297908</td>\n",
       "      <td>-0.631857</td>\n",
       "      <td>0.471115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.598362</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>0.297908</td>\n",
       "      <td>-0.631857</td>\n",
       "      <td>0.308764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.519062</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>0.297908</td>\n",
       "      <td>-0.631857</td>\n",
       "      <td>0.181203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.408041</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>0.297908</td>\n",
       "      <td>-0.631857</td>\n",
       "      <td>0.311663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.281161</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>0.297908</td>\n",
       "      <td>-0.631857</td>\n",
       "      <td>0.258030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.122560</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>0.297908</td>\n",
       "      <td>-0.631857</td>\n",
       "      <td>-0.105809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.083620</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>0.297908</td>\n",
       "      <td>-0.631857</td>\n",
       "      <td>-0.231921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.353241</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>0.297908</td>\n",
       "      <td>-0.631857</td>\n",
       "      <td>-0.540677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.670443</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>0.297908</td>\n",
       "      <td>-0.631857</td>\n",
       "      <td>-0.758110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.082804</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>0.297908</td>\n",
       "      <td>-0.631857</td>\n",
       "      <td>-0.994388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.622046</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>0.297908</td>\n",
       "      <td>-0.631857</td>\n",
       "      <td>-1.211822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.256449</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>0.297908</td>\n",
       "      <td>-0.631857</td>\n",
       "      <td>-1.704671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.049452</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>0.297908</td>\n",
       "      <td>-0.631857</td>\n",
       "      <td>-1.994583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.852123</td>\n",
       "      <td>-1.146021</td>\n",
       "      <td>1.798701</td>\n",
       "      <td>-0.723104</td>\n",
       "      <td>-0.611282</td>\n",
       "      <td>-0.972210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>-0.852123</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>2.477980</td>\n",
       "      <td>0.878730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>-0.836263</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>2.477980</td>\n",
       "      <td>1.061374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>-0.815645</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>2.477980</td>\n",
       "      <td>1.300551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>-0.788683</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>2.477980</td>\n",
       "      <td>1.336790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>-0.756963</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>2.477980</td>\n",
       "      <td>0.841042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>-0.715727</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>2.477980</td>\n",
       "      <td>-0.369339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>-0.661802</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>2.477980</td>\n",
       "      <td>-0.093923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>-0.598362</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>2.477980</td>\n",
       "      <td>-0.057684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>-0.519062</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>2.477980</td>\n",
       "      <td>-0.240328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>-0.408041</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>2.477980</td>\n",
       "      <td>-0.479505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>-0.281161</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>2.477980</td>\n",
       "      <td>-0.717233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>-0.122560</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>2.477980</td>\n",
       "      <td>-0.846243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>0.083620</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>2.477980</td>\n",
       "      <td>-1.212981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>0.353241</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>1.312498</td>\n",
       "      <td>2.477980</td>\n",
       "      <td>-1.672491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>-0.852123</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>-0.723104</td>\n",
       "      <td>3.171717</td>\n",
       "      <td>-0.191623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>-0.836263</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>-0.723104</td>\n",
       "      <td>3.171717</td>\n",
       "      <td>-0.027823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>-0.815645</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>-0.723104</td>\n",
       "      <td>3.171717</td>\n",
       "      <td>-0.301790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>-0.788683</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>-0.723104</td>\n",
       "      <td>3.171717</td>\n",
       "      <td>-0.630839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>-0.756963</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>-0.723104</td>\n",
       "      <td>3.171717</td>\n",
       "      <td>-1.381710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>-0.715727</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>-0.723104</td>\n",
       "      <td>3.171717</td>\n",
       "      <td>-0.978733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>-0.661802</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>-0.723104</td>\n",
       "      <td>3.171717</td>\n",
       "      <td>-0.851172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>-0.598362</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>-0.723104</td>\n",
       "      <td>3.171717</td>\n",
       "      <td>-0.813483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>-0.519062</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>-0.723104</td>\n",
       "      <td>3.171717</td>\n",
       "      <td>-0.959889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>-0.408041</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>-0.723104</td>\n",
       "      <td>3.171717</td>\n",
       "      <td>-1.490427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>-0.281161</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>-0.723104</td>\n",
       "      <td>3.171717</td>\n",
       "      <td>-2.020965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>-0.122560</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>-0.723104</td>\n",
       "      <td>3.171717</td>\n",
       "      <td>-2.112287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>0.083620</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>-0.723104</td>\n",
       "      <td>3.171717</td>\n",
       "      <td>-2.258692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>0.353241</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>-0.723104</td>\n",
       "      <td>3.171717</td>\n",
       "      <td>-2.642825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>0.670443</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>-0.723104</td>\n",
       "      <td>3.171717</td>\n",
       "      <td>-2.697908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>1.082804</td>\n",
       "      <td>1.489947</td>\n",
       "      <td>-0.373615</td>\n",
       "      <td>-0.723104</td>\n",
       "      <td>3.171717</td>\n",
       "      <td>-2.990719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1503 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Frequency  Angle of Attack  Chord Length  Free-Steam Velocity  \\\n",
       "0     -0.661802        -1.146021      1.798701             1.312498   \n",
       "1     -0.598362        -1.146021      1.798701             1.312498   \n",
       "2     -0.519062        -1.146021      1.798701             1.312498   \n",
       "3     -0.408041        -1.146021      1.798701             1.312498   \n",
       "4     -0.281161        -1.146021      1.798701             1.312498   \n",
       "5     -0.122560        -1.146021      1.798701             1.312498   \n",
       "6      0.083620        -1.146021      1.798701             1.312498   \n",
       "7      0.353241        -1.146021      1.798701             1.312498   \n",
       "8      0.670443        -1.146021      1.798701             1.312498   \n",
       "9      1.082804        -1.146021      1.798701             1.312498   \n",
       "10     1.622046        -1.146021      1.798701             1.312498   \n",
       "11     2.256449        -1.146021      1.798701             1.312498   \n",
       "12     3.049452        -1.146021      1.798701             1.312498   \n",
       "13     4.159656        -1.146021      1.798701             1.312498   \n",
       "14    -0.756963        -1.146021      1.798701             0.297908   \n",
       "15    -0.715727        -1.146021      1.798701             0.297908   \n",
       "16    -0.661802        -1.146021      1.798701             0.297908   \n",
       "17    -0.598362        -1.146021      1.798701             0.297908   \n",
       "18    -0.519062        -1.146021      1.798701             0.297908   \n",
       "19    -0.408041        -1.146021      1.798701             0.297908   \n",
       "20    -0.281161        -1.146021      1.798701             0.297908   \n",
       "21    -0.122560        -1.146021      1.798701             0.297908   \n",
       "22     0.083620        -1.146021      1.798701             0.297908   \n",
       "23     0.353241        -1.146021      1.798701             0.297908   \n",
       "24     0.670443        -1.146021      1.798701             0.297908   \n",
       "25     1.082804        -1.146021      1.798701             0.297908   \n",
       "26     1.622046        -1.146021      1.798701             0.297908   \n",
       "27     2.256449        -1.146021      1.798701             0.297908   \n",
       "28     3.049452        -1.146021      1.798701             0.297908   \n",
       "29    -0.852123        -1.146021      1.798701            -0.723104   \n",
       "...         ...              ...           ...                  ...   \n",
       "1473  -0.852123         1.489947     -0.373615             1.312498   \n",
       "1474  -0.836263         1.489947     -0.373615             1.312498   \n",
       "1475  -0.815645         1.489947     -0.373615             1.312498   \n",
       "1476  -0.788683         1.489947     -0.373615             1.312498   \n",
       "1477  -0.756963         1.489947     -0.373615             1.312498   \n",
       "1478  -0.715727         1.489947     -0.373615             1.312498   \n",
       "1479  -0.661802         1.489947     -0.373615             1.312498   \n",
       "1480  -0.598362         1.489947     -0.373615             1.312498   \n",
       "1481  -0.519062         1.489947     -0.373615             1.312498   \n",
       "1482  -0.408041         1.489947     -0.373615             1.312498   \n",
       "1483  -0.281161         1.489947     -0.373615             1.312498   \n",
       "1484  -0.122560         1.489947     -0.373615             1.312498   \n",
       "1485   0.083620         1.489947     -0.373615             1.312498   \n",
       "1486   0.353241         1.489947     -0.373615             1.312498   \n",
       "1487  -0.852123         1.489947     -0.373615            -0.723104   \n",
       "1488  -0.836263         1.489947     -0.373615            -0.723104   \n",
       "1489  -0.815645         1.489947     -0.373615            -0.723104   \n",
       "1490  -0.788683         1.489947     -0.373615            -0.723104   \n",
       "1491  -0.756963         1.489947     -0.373615            -0.723104   \n",
       "1492  -0.715727         1.489947     -0.373615            -0.723104   \n",
       "1493  -0.661802         1.489947     -0.373615            -0.723104   \n",
       "1494  -0.598362         1.489947     -0.373615            -0.723104   \n",
       "1495  -0.519062         1.489947     -0.373615            -0.723104   \n",
       "1496  -0.408041         1.489947     -0.373615            -0.723104   \n",
       "1497  -0.281161         1.489947     -0.373615            -0.723104   \n",
       "1498  -0.122560         1.489947     -0.373615            -0.723104   \n",
       "1499   0.083620         1.489947     -0.373615            -0.723104   \n",
       "1500   0.353241         1.489947     -0.373615            -0.723104   \n",
       "1501   0.670443         1.489947     -0.373615            -0.723104   \n",
       "1502   1.082804         1.489947     -0.373615            -0.723104   \n",
       "\n",
       "      Suction side displacement thickness  Scaled sound pressure level  \n",
       "0                               -0.644590                     0.197873  \n",
       "1                               -0.644590                     0.052917  \n",
       "2                               -0.644590                     0.161634  \n",
       "3                               -0.644590                     0.399361  \n",
       "4                               -0.644590                     0.380517  \n",
       "5                               -0.644590                     0.106551  \n",
       "6                               -0.644590                     0.052917  \n",
       "7                               -0.644590                    -0.257288  \n",
       "8                               -0.644590                    -0.512410  \n",
       "9                               -0.644590                    -0.767532  \n",
       "10                              -0.644590                    -1.113977  \n",
       "11                              -0.644590                    -1.369099  \n",
       "12                              -0.644590                    -1.825709  \n",
       "13                              -0.644590                    -2.335954  \n",
       "14                              -0.631857                     0.229038  \n",
       "15                              -0.631857                     0.414582  \n",
       "16                              -0.631857                     0.471115  \n",
       "17                              -0.631857                     0.308764  \n",
       "18                              -0.631857                     0.181203  \n",
       "19                              -0.631857                     0.311663  \n",
       "20                              -0.631857                     0.258030  \n",
       "21                              -0.631857                    -0.105809  \n",
       "22                              -0.631857                    -0.231921  \n",
       "23                              -0.631857                    -0.540677  \n",
       "24                              -0.631857                    -0.758110  \n",
       "25                              -0.631857                    -0.994388  \n",
       "26                              -0.631857                    -1.211822  \n",
       "27                              -0.631857                    -1.704671  \n",
       "28                              -0.631857                    -1.994583  \n",
       "29                              -0.611282                    -0.972210  \n",
       "...                                   ...                          ...  \n",
       "1473                             2.477980                     0.878730  \n",
       "1474                             2.477980                     1.061374  \n",
       "1475                             2.477980                     1.300551  \n",
       "1476                             2.477980                     1.336790  \n",
       "1477                             2.477980                     0.841042  \n",
       "1478                             2.477980                    -0.369339  \n",
       "1479                             2.477980                    -0.093923  \n",
       "1480                             2.477980                    -0.057684  \n",
       "1481                             2.477980                    -0.240328  \n",
       "1482                             2.477980                    -0.479505  \n",
       "1483                             2.477980                    -0.717233  \n",
       "1484                             2.477980                    -0.846243  \n",
       "1485                             2.477980                    -1.212981  \n",
       "1486                             2.477980                    -1.672491  \n",
       "1487                             3.171717                    -0.191623  \n",
       "1488                             3.171717                    -0.027823  \n",
       "1489                             3.171717                    -0.301790  \n",
       "1490                             3.171717                    -0.630839  \n",
       "1491                             3.171717                    -1.381710  \n",
       "1492                             3.171717                    -0.978733  \n",
       "1493                             3.171717                    -0.851172  \n",
       "1494                             3.171717                    -0.813483  \n",
       "1495                             3.171717                    -0.959889  \n",
       "1496                             3.171717                    -1.490427  \n",
       "1497                             3.171717                    -2.020965  \n",
       "1498                             3.171717                    -2.112287  \n",
       "1499                             3.171717                    -2.258692  \n",
       "1500                             3.171717                    -2.642825  \n",
       "1501                             3.171717                    -2.697908  \n",
       "1502                             3.171717                    -2.990719  \n",
       "\n",
       "[1503 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputData = (inputData - inputData.mean()) / inputData.std()\n",
    "inputData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим целевой столбец, им будет искомый \"Scaled sound pressure level\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targetColumn = 'Scaled sound pressure level'\n",
    "\n",
    "# Получим имена всех столбцов и удалим оттуда целевой столбец\n",
    "FeatureColumns = inputData.columns.tolist()\n",
    "FeatureColumns.remove(targetColumn)\n",
    "#FeatureColumns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В таблице могут содержаться пропущенные значения. Проверим, есть ли они в наших данных и если есть, то сколько их:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values: False\n",
      "Count of NaN values: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Null values: {0}\".format(inputData.isnull().values.any()))\n",
    "print(\"Count of NaN values: {0}\".format(np.sum(inputData.isnull().values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы выяснили, пропущенных значений нет. Далее проверим тип данных, чтобы убедиться, что в таблице отсутствуют нечисловые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Frequency                              float64\n",
       "Angle of Attack                        float64\n",
       "Chord Length                           float64\n",
       "Free-Steam Velocity                    float64\n",
       "Suction side displacement thickness    float64\n",
       "Scaled sound pressure level            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputData.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все данные в нашей таблице - числовые"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продолжим работу с данными. \n",
    "Далее приступим к анализу данных.\n",
    "X  - матрица атрибутов данных и  y -  вектор значений целевой переменной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала попробуем использовать стандартную линейную регрессию из пакета scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = inputData[FeatureColumns].values\n",
    "y = inputData[targetColumn].values\n",
    "\n",
    "# Сначала импортируем класс, реализующий линейную регрессию\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# После чего создадим объект класса и выполним подгон данных по всей выборке\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X,y) # Подгон данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После получения линейной регрессии, мы можем посмотреть коэффициенты и смещение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:  3.3404375099e-14\n",
      "Coefficients:  [-0.58594766 -0.36194402 -0.48390314  0.225407   -0.28078457]\n"
     ]
    }
   ],
   "source": [
    "print(\"Intercept: \", lr.intercept_)\n",
    "print(\"Coefficients: \", lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE : 0.5404700651314962\n",
      "MSE : 0.4839680421666699\n",
      "R^2 coefficient : 0.5157097420928733\n",
      "RMSE : 0.6956781167800737\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Получим вектор \"предсказаний\"\n",
    "y_predict = lr.predict(X)\n",
    "# В функцию передается истинное значение вектора ответов и предсказанное нашей регрессионной функцией:\n",
    "test_mae_error = mean_absolute_error(y, y_predict)\n",
    "test_mse_error = mean_squared_error(y, y_predict)\n",
    "test_r2_error = r2_score(y, y_predict)\n",
    "test_rmse_error = math.sqrt(test_mse_error)\n",
    "print(\"MAE : {0}\".format(test_mae_error))\n",
    "print(\"MSE : {0}\".format(test_mse_error))\n",
    "print(\"R^2 coefficient : {0}\".format(test_r2_error))\n",
    "print(\"RMSE : {0}\".format(test_rmse_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #1: MAE : 0.5380993954594238, MSE : 0.45656836657377736, R2 : 0.5310789665691015\n",
      "Iteration #2: MAE : 0.49797588606844134, MSE : 0.4032507170288285, R2 : 0.5390534073644937\n",
      "Iteration #3: MAE : 0.6378459300828798, MSE : 0.6362399279624593, R2 : 0.5033915924071257\n",
      "Iteration #4: MAE : 0.5486709210326537, MSE : 0.5333252404417071, R2 : 0.4280792390874919\n",
      "Iteration #5: MAE : 0.5768494764431712, MSE : 0.5749362134043651, R2 : 0.5191839703898657\n",
      "Iteration #6: MAE : 0.5252881288269251, MSE : 0.4426214084460374, R2 : 0.4381729097026602\n",
      "Iteration #7: MAE : 0.4997826298849402, MSE : 0.44322375021279203, R2 : 0.5350236182074686\n",
      "Iteration #8: MAE : 0.5267099055662459, MSE : 0.44467904057711594, R2 : 0.5454852253189014\n",
      "Iteration #9: MAE : 0.5442230474402849, MSE : 0.5064130026641124, R2 : 0.5015671129522749\n",
      "Iteration #10: MAE : 0.5333673601052566, MSE : 0.4435800328328896, R2 : 0.5419162511260871\n",
      "\n",
      "Overall: \n",
      "\tMAE : 0.5428812680910222\n",
      "\tMSE : 0.4884837700144084\n",
      "\tR^2 coefficient : 0.5082952293125471\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "MAE_list_scores = []\n",
    "MSE_list_scores = []\n",
    "R2_list_scores = []\n",
    "\n",
    "iteration_index = 0\n",
    "\n",
    "# Разделение на тестовую и тренировочную выборки\n",
    "for train_indexes, test_indexes in kf.split(X,y):\n",
    "    iteration_index+=1\n",
    "    # X_train, y_train - данные, соответствующие обучающей выборке\n",
    "    X_train = X[train_indexes]\n",
    "    y_train = y[train_indexes]\n",
    "    \n",
    "    # X_test, y_test - данные, соответствующие тренировочной выборке\n",
    "    X_test = X[test_indexes]\n",
    "    y_test = y[test_indexes]\n",
    "    \n",
    "    lr.fit(X_train, y_train) # Обучение на тестовых данных\n",
    "    y_predict = lr.predict(X_test)\n",
    "    \n",
    "    current_mae = mean_absolute_error(y_test, y_predict)\n",
    "    current_mse = mean_squared_error(y_test, y_predict)\n",
    "    current_r2 = r2_score(y_test, y_predict)\n",
    "    print(\"Iteration #{0}: MAE : {1}, MSE : {2}, R2 : {3}\".format(iteration_index, current_mae, current_mse, current_r2))\n",
    "    MAE_list_scores.append(current_mae)\n",
    "    MSE_list_scores.append(current_mse)\n",
    "    R2_list_scores.append(current_r2)\n",
    "\n",
    "# Выведем средние значения:\n",
    "print(\"\\nOverall: \")\n",
    "print(\"\\tMAE : {0}\".format(np.mean(MAE_list_scores)))\n",
    "print(\"\\tMSE : {0}\".format(np.mean(MSE_list_scores)))\n",
    "print(\"\\tR^2 coefficient : {0}\".format(np.mean(R2_list_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mse_error < np.mean(MSE_list_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Полиномиальная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 0\n",
      "\tMAE : 0.8169818333773069\n",
      "\tMSE : 0.9998429825336261\n",
      "Degree: 1\n",
      "\tMAE : 0.5417848588940666\n",
      "\tMSE : 0.4864285739776572\n",
      "Degree: 2\n",
      "\tMAE : 0.466261353597056\n",
      "\tMSE : 0.36803090945291445\n",
      "Degree: 3\n",
      "\tMAE : 0.39024260728810756\n",
      "\tMSE : 0.2613775678736438\n",
      "Degree: 4\n",
      "\tMAE : 0.31654808959460573\n",
      "\tMSE : 0.18937285830828668\n",
      "Degree: 5\n",
      "\tMAE : 0.3052049155038964\n",
      "\tMSE : 0.26220012468274084\n",
      "Degree: 6\n",
      "\tMAE : 0.39542464980731656\n",
      "\tMSE : 2.33538791966857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "degreeList = []\n",
    "maeList = []\n",
    "mseList = []\n",
    "\n",
    "kf = KFold(n_splits=7, shuffle=True)\n",
    "\n",
    "for count, degree in enumerate(range(0,7)):\n",
    "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    \n",
    "    MAE_for_current_degree = []\n",
    "    MSE_for_current_degree = []\n",
    "    \n",
    "    for train_indexes, test_indexes in kf.split(X,y):\n",
    "        # X_train, y_train - данные, соответствующие обучающей выборке\n",
    "        X_train = X[train_indexes]\n",
    "        y_train = y[train_indexes]\n",
    "    \n",
    "        # X_test, y_test - данные, соответствующие тренировочной выборке\n",
    "        X_test = X[test_indexes]\n",
    "        y_test = y[test_indexes]\n",
    "    \n",
    "        model.fit(X_train, y_train) # Обучение на тестовых данных\n",
    "        y_predict = model.predict(X_test)\n",
    "        \n",
    "        current_mae = mean_absolute_error(y_test, y_predict)\n",
    "        current_mse = mean_squared_error(y_test, y_predict)\n",
    "        \n",
    "        MAE_for_current_degree.append(current_mae)\n",
    "        MSE_for_current_degree.append(current_mse)\n",
    "    \n",
    "    print(\"Degree: {0}\".format(degree))\n",
    "    print(\"\\tMAE : {0}\".format(np.mean(MAE_for_current_degree)))\n",
    "    print(\"\\tMSE : {0}\".format(np.mean(MSE_for_current_degree)))\n",
    "    degreeList.append(degree)\n",
    "    maeList.append(np.mean(MAE_for_current_degree))\n",
    "    mseList.append(np.mean(MSE_for_current_degree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAGHCAYAAAD2qfsmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDREREYmNgoaIiIjE5v8HcEfnSW6SMEMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b3b89f2ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAGHCAYAAAD2qfsmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nISIiIlnzf+CEdeAx0QaMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b3b8a51a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(degreeList, mseList, 'b-', label='MSE')\n",
    "plt.title('MSE Error')\n",
    "plt.ylabel('MSE Error')\n",
    "plt.xlabel('Degree of polynomial')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(degreeList, maeList, 'r', label='MAE')\n",
    "plt.title('MAE Error')\n",
    "plt.ylabel('MAE Error')\n",
    "plt.xlabel('Degree of polynomial')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = make_pipeline(PolynomialFeatures(1), LinearRegression())\n",
    "model.fit(X_train, y_train) # Обучение на тестовых данных\n",
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ 0.         -0.57151253 -0.38314912 -0.49013796  0.22593811 -0.26288612]\n",
      "Intercept: 0.000539339567224976\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients: {0}\".format((model.get_params()['linearregression']).coef_))\n",
    "print(\"Intercept: {0}\".format((model.get_params()['linearregression']).intercept_ ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMAE : 0.5436274648658364\n",
      "\tMSE : 0.4902942639008588\n",
      "Coefficients: [ 0.         -0.56936791 -0.37101769 -0.47531609  0.21711783 -0.26802147]\n",
      "Intercept: -0.012222403878225216\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Мы выяснили, что оптимальным значением степени для полиномиальной регрессии является 1, поэтому укажем её.\n",
    "optimalDegree = 4\n",
    "\n",
    "# Будем использовать параметры по умолчанию, т.е. на данный момент не укажем значение alpha\n",
    "model = make_pipeline(PolynomialFeatures(1), Ridge())\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "MAE_list = []\n",
    "MSE_list = []\n",
    "\n",
    "for train_indexes, test_indexes in kf.split(X,y):\n",
    "    # X_train, y_train - данные, соответствующие обучающей выборке\n",
    "    X_train = X[train_indexes]\n",
    "    y_train = y[train_indexes]\n",
    "    \n",
    "    # X_test, y_test - данные, соответствующие тренировочной выборке\n",
    "    X_test = X[test_indexes]\n",
    "    y_test = y[test_indexes]\n",
    "    \n",
    "    model.fit(X_train, y_train) # Обучение на тестовых данных\n",
    "    y_predict = model.predict(X_test)\n",
    "        \n",
    "    current_mae = mean_absolute_error(y_test, y_predict)\n",
    "    current_mse = mean_squared_error(y_test, y_predict)\n",
    "        \n",
    "    MAE_list.append(current_mae)\n",
    "    MSE_list.append(current_mse)\n",
    "print(\"\\tMAE : {0}\".format(np.mean(MAE_list)))\n",
    "print(\"\\tMSE : {0}\".format(np.mean(MSE_list)))    \n",
    "\n",
    "print(\"Coefficients: {0}\".format((model.get_params()['ridge']).coef_))\n",
    "print(\"Intercept: {0}\".format((model.get_params()['ridge']).intercept_ ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос:\n",
    "**Сравните и объясните полученные значения MSE и весовых коэффициентов $L_2$-регрессии со значениями линейной регрессии** \n",
    "\n",
    "При линейной регрессии значение MSE получилось меньше, самое меньшее значение мы получили с помощью полиномиальной регрессии при 5-й степени"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $L_1$ регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMAE : 0.8170457214483801\n",
      "\tMSE : 1.0002807745587736\n",
      "Coefficients: [ 0. -0. -0. -0.  0. -0.]\n",
      "Intercept: -0.002314533426432345\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(PolynomialFeatures(1), Lasso())\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "MAE_list = []\n",
    "MSE_list = []\n",
    "\n",
    "for train_indexes, test_indexes in kf.split(X,y):\n",
    "    # X_train, y_train - данные, соответствующие обучающей выборке\n",
    "    X_train = X[train_indexes]\n",
    "    y_train = y[train_indexes]\n",
    "    \n",
    "    # X_test, y_test - данные, соответствующие тренировочной выборке\n",
    "    X_test = X[test_indexes]\n",
    "    y_test = y[test_indexes]\n",
    "    \n",
    "    model.fit(X_train, y_train) # Обучение на тестовых данных\n",
    "    y_predict = model.predict(X_test)\n",
    "        \n",
    "    current_mae = mean_absolute_error(y_test, y_predict)\n",
    "    current_mse = mean_squared_error(y_test, y_predict)\n",
    "        \n",
    "    MAE_list.append(current_mae)\n",
    "    MSE_list.append(current_mse)\n",
    "print(\"\\tMAE : {0}\".format(np.mean(MAE_list)))\n",
    "print(\"\\tMSE : {0}\".format(np.mean(MSE_list)))    \n",
    "\n",
    "print(\"Coefficients: {0}\".format((model.get_params()['lasso']).coef_))\n",
    "print(\"Intercept: {0}\".format((model.get_params()['lasso']).intercept_ ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопросы:\n",
    "\n",
    "** Сравните и объясните полученные значения MSE и весовых коэффициентов $L_1$-регрессии со значениями линейной регрессии**\n",
    "Значение метрики MSE при линейной регрессии получилось меньше, чем значение MSE при L2, сделовательно лиейная регрессии оказалась эффективнее.\n",
    "\n",
    "** Какие значения были отброшены моделью, в процессе $L_1$-регуляризации? **\n",
    "В процессе L1 регуляризации были отброшены значения 3-го и 5-го признаков из сета данных (Chord Length и Suction side displacement thickness), так как модель присвоила им нулевые коэффиценты.\n",
    "\n",
    "** Сравните и объясните полученные значения MSE и весовых коэффициентов $L_1$-регрессии со значениями $L_2$-регрессии**\n",
    "Значение MSE у Ridge регрессии ближе к данным, полученным изначально, значение у Lasso значительно отличается. \n",
    "\n",
    "** Что лучше использовать для данной задачи: $L_1$ или $L_2$ регрессию?**\n",
    "Для данной задачи лучше использовать Ridge регуляризацию, так как она более устойчива для данного набора данных и она более эффективна при наличии кореллирующих признаков (в данном наборе 4 и 5 столбцы)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор гиперпараметра в задаче регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "MAE_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "MSE_scorer = make_scorer(mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e-10,   1.14895100e-10,   1.32008840e-10,\n",
       "         1.51671689e-10,   1.74263339e-10,   2.00220037e-10,\n",
       "         2.30043012e-10,   2.64308149e-10,   3.03677112e-10,\n",
       "         3.48910121e-10,   4.00880633e-10,   4.60592204e-10,\n",
       "         5.29197874e-10,   6.08022426e-10,   6.98587975e-10,\n",
       "         8.02643352e-10,   9.22197882e-10,   1.05956018e-09,\n",
       "         1.21738273e-09,   1.39871310e-09,   1.60705282e-09,\n",
       "         1.84642494e-09,   2.12145178e-09,   2.43744415e-09,\n",
       "         2.80050389e-09,   3.21764175e-09,   3.69691271e-09,\n",
       "         4.24757155e-09,   4.88025158e-09,   5.60716994e-09,\n",
       "         6.44236351e-09,   7.40196000e-09,   8.50448934e-09,\n",
       "         9.77124154e-09,   1.12266777e-08,   1.28989026e-08,\n",
       "         1.48202071e-08,   1.70276917e-08,   1.95639834e-08,\n",
       "         2.24780583e-08,   2.58261876e-08,   2.96730241e-08,\n",
       "         3.40928507e-08,   3.91710149e-08,   4.50055768e-08,\n",
       "         5.17092024e-08,   5.94113398e-08,   6.82607183e-08,\n",
       "         7.84282206e-08,   9.01101825e-08,   1.03532184e-07,\n",
       "         1.18953407e-07,   1.36671636e-07,   1.57029012e-07,\n",
       "         1.80418641e-07,   2.07292178e-07,   2.38168555e-07,\n",
       "         2.73644000e-07,   3.14403547e-07,   3.61234270e-07,\n",
       "         4.15040476e-07,   4.76861170e-07,   5.47890118e-07,\n",
       "         6.29498899e-07,   7.23263390e-07,   8.30994195e-07,\n",
       "         9.54771611e-07,   1.09698580e-06,   1.26038293e-06,\n",
       "         1.44811823e-06,   1.66381689e-06,   1.91164408e-06,\n",
       "         2.19638537e-06,   2.52353917e-06,   2.89942285e-06,\n",
       "         3.33129479e-06,   3.82749448e-06,   4.39760361e-06,\n",
       "         5.05263107e-06,   5.80522552e-06,   6.66991966e-06,\n",
       "         7.66341087e-06,   8.80488358e-06,   1.01163798e-05,\n",
       "         1.16232247e-05,   1.33545156e-05,   1.53436841e-05,\n",
       "         1.76291412e-05,   2.02550194e-05,   2.32720248e-05,\n",
       "         2.67384162e-05,   3.07211300e-05,   3.52970730e-05,\n",
       "         4.05546074e-05,   4.65952567e-05,   5.35356668e-05,\n",
       "         6.15098579e-05,   7.06718127e-05,   8.11984499e-05,\n",
       "         9.32930403e-05,   1.07189132e-04,   1.23155060e-04,\n",
       "         1.41499130e-04,   1.62575567e-04,   1.86791360e-04,\n",
       "         2.14614120e-04,   2.46581108e-04,   2.83309610e-04,\n",
       "         3.25508860e-04,   3.73993730e-04,   4.29700470e-04,\n",
       "         4.93704785e-04,   5.67242607e-04,   6.51733960e-04,\n",
       "         7.48810386e-04,   8.60346442e-04,   9.88495905e-04,\n",
       "         1.13573336e-03,   1.30490198e-03,   1.49926843e-03,\n",
       "         1.72258597e-03,   1.97916687e-03,   2.27396575e-03,\n",
       "         2.61267523e-03,   3.00183581e-03,   3.44896226e-03,\n",
       "         3.96268864e-03,   4.55293507e-03,   5.23109931e-03,\n",
       "         6.01027678e-03,   6.90551352e-03,   7.93409667e-03,\n",
       "         9.11588830e-03,   1.04737090e-02,   1.20337784e-02,\n",
       "         1.38262217e-02,   1.58856513e-02,   1.82518349e-02,\n",
       "         2.09704640e-02,   2.40940356e-02,   2.76828663e-02,\n",
       "         3.18062569e-02,   3.65438307e-02,   4.19870708e-02,\n",
       "         4.82410870e-02,   5.54266452e-02,   6.36824994e-02,\n",
       "         7.31680714e-02,   8.40665289e-02,   9.65883224e-02,\n",
       "         1.10975250e-01,   1.27505124e-01,   1.46497140e-01,\n",
       "         1.68318035e-01,   1.93389175e-01,   2.22194686e-01,\n",
       "         2.55290807e-01,   2.93316628e-01,   3.37006433e-01,\n",
       "         3.87203878e-01,   4.44878283e-01,   5.11143348e-01,\n",
       "         5.87278661e-01,   6.74754405e-01,   7.75259749e-01,\n",
       "         8.90735464e-01,   1.02341140e+00,   1.17584955e+00,\n",
       "         1.35099352e+00,   1.55222536e+00,   1.78343088e+00,\n",
       "         2.04907469e+00,   2.35428641e+00,   2.70495973e+00,\n",
       "         3.10786619e+00,   3.57078596e+00,   4.10265811e+00,\n",
       "         4.71375313e+00,   5.41587138e+00,   6.22257084e+00,\n",
       "         7.14942899e+00,   8.21434358e+00,   9.43787828e+00,\n",
       "         1.08436597e+01,   1.24588336e+01,   1.43145894e+01,\n",
       "         1.64467618e+01,   1.88965234e+01,   2.17111795e+01,\n",
       "         2.49450814e+01,   2.86606762e+01,   3.29297126e+01,\n",
       "         3.78346262e+01,   4.34701316e+01,   4.99450512e+01,\n",
       "         5.73844165e+01,   6.59318827e+01,   7.57525026e+01,\n",
       "         8.70359136e+01,   1.00000000e+02])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_alphas = 200 # 200 значений\n",
    "alphas = np.logspace(-10, 2, n_alphas)\n",
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters = {'alpha':alphas}\n",
    "parameters = {'alpha': alphas, 'fit_intercept' : [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': array([  1.00000e-10,   1.14895e-10, ...,   8.70359e+01,   1.00000e+02]), 'fit_intercept': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(Ridge(), parameters, scoring  = MAE_scorer) \n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1e-10, 'fit_intercept': False}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.55528547220923608"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1e-10, copy_X=True, fit_intercept=False, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': array([  1.00000e-10,   1.14895e-10, ...,   8.70359e+01,   1.00000e+02]), 'fit_intercept': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(mean_squared_error, greater_is_better=False),\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = GridSearchCV(Ridge(), parameters, scoring  = MSE_scorer)\n",
    "clf1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 6.222570836730231, 'fit_intercept': False}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.51172685942043794"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=6.222570836730231, copy_X=True, fit_intercept=False,\n",
       "   max_iter=None, normalize=False, random_state=None, solver='auto',\n",
       "   tol=0.001)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMAE : 0.3261237942813048\n",
      "\tMSE : 0.223985068041271\n",
      "Coefficients: [  2.67255135e+00  -1.66510269e+00  -1.34386402e+01  -2.47213054e+00\n",
      "   1.55497739e+00   1.14696860e+01   2.61883436e-01  -1.06161575e+00\n",
      "   4.25685070e-01   8.33006875e-02   7.07810726e-02  -3.77477516e-01\n",
      "  -1.29862937e+01  -8.53971733e-01  -2.38258228e+01  -2.48360694e+00\n",
      "   4.32531476e-01   6.39776171e+00   1.55663684e-01   1.78866784e+00\n",
      "   1.04272157e+01   3.53619090e-01  -4.37740740e-01   7.43291420e-01\n",
      "  -7.87050318e-02   1.76363770e+00  -2.11118250e+00  -3.56222084e+00\n",
      "   1.67769279e-01   2.77725379e+00  -2.58452840e-01   6.18583362e-02\n",
      "   3.21391365e+00  -6.17406314e-02  -1.77370870e-01  -3.66099597e-01\n",
      "   2.84751182e+00   1.63708279e+01  -1.15897603e+00  -5.89670842e+00\n",
      "   1.05196498e+01  -1.86511440e+00  -4.42551018e+01   7.58945028e-01\n",
      "   1.19097916e+00  -3.16326209e+00   2.94474028e+00  -3.03328943e-01\n",
      "  -7.78111006e+00   3.73784479e-01   2.44954625e+00   1.92643193e+01\n",
      "  -7.44841763e-02  -1.07022134e+00  -5.29609223e-01  -3.20582392e-01\n",
      "  -4.03330449e-02   8.23071263e-02  -6.20426483e-02   6.67822553e-03\n",
      "  -8.90082342e-02   3.23155032e-02   4.90392454e-02  -2.99715478e-02\n",
      "  -9.54935344e-04  -1.09489684e-01   4.11298323e-03   5.66211572e-01\n",
      "  -8.08748848e-03  -4.54479873e-02  -4.50640213e-01   8.25718958e-01\n",
      "   6.83770833e-01  -1.23316145e-01  -3.10574875e+00   4.81529662e-01\n",
      "  -1.64825739e-01  -4.38658169e+00   1.44387185e-02   3.59429560e-01\n",
      "   1.51092588e+00  -1.62586035e-01   2.57390275e-03  -1.23869968e+00\n",
      "   1.16892411e-02   2.20230049e-01   8.82353891e-01   8.25004933e-03\n",
      "   2.24893814e-02  -1.34010508e-01  -2.67223870e-01   2.21195983e+00\n",
      "  -3.47778039e+00  -1.25315536e-01  -3.74432423e+00  -1.75539165e+00\n",
      "  -1.35306765e-01   2.65073000e+01   2.53343698e-01  -1.78881701e+00\n",
      "   8.84884251e-01  -1.01864475e+00  -2.79357066e-01   1.28732956e+01\n",
      "   1.58827150e-01  -1.97893047e+00  -3.10902608e+01  -2.18664539e-01\n",
      "   2.53723571e-01   4.54355527e+00   5.33640973e+00  -6.00071578e-01\n",
      "  -3.25526386e-02   2.92874202e+00  -3.94634188e-03   8.68950223e-02\n",
      "  -1.51670206e+00  -5.76334047e-02   2.14895261e-01   2.21554086e+00\n",
      "   7.86878255e+00  -3.29077191e-01   3.19783618e-01   1.01832613e-01\n",
      "  -1.84762891e+00  -1.81500525e+00]\n",
      "Intercept: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Мы выяснили, что оптимальным значением степени для полиномиальной регрессии является 4, поэтому укажем её.\n",
    "optimalDegree = 4\n",
    "\n",
    "# передаем лучший estimator, подобранный с помощью GridSearchCV\n",
    "model = make_pipeline(PolynomialFeatures(4), clf.best_estimator_)\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "MAE_list = []\n",
    "MSE_list = []\n",
    "\n",
    "for train_indexes, test_indexes in kf.split(X,y):\n",
    "    # X_train, y_train - данные, соответствующие обучающей выборке\n",
    "    X_train = X[train_indexes]\n",
    "    y_train = y[train_indexes]\n",
    "    \n",
    "    # X_test, y_test - данные, соответствующие тренировочной выборке\n",
    "    X_test = X[test_indexes]\n",
    "    y_test = y[test_indexes]\n",
    "    \n",
    "    model.fit(X_train, y_train) # Обучение на тестовых данных\n",
    "    y_predict = model.predict(X_test)\n",
    "        \n",
    "    current_mae = mean_absolute_error(y_test, y_predict)\n",
    "    current_mse = mean_squared_error(y_test, y_predict)\n",
    "        \n",
    "    MAE_list.append(current_mae)\n",
    "    MSE_list.append(current_mse)\n",
    "print(\"\\tMAE : {0}\".format(np.mean(MAE_list)))\n",
    "print(\"\\tMSE : {0}\".format(np.mean(MSE_list)))    \n",
    "\n",
    "print(\"Coefficients: {0}\".format((model.get_params()['ridge']).coef_))\n",
    "print(\"Intercept: {0}\".format((model.get_params()['ridge']).intercept_ ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('polynomialfeatures', PolynomialFeatures(degree=4, include_bias=True, interaction_only=False)), ('ridge', Ridge(alpha=1e-10, copy_X=True, fit_intercept=False, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'ridge__alpha': alphas, 'ridge__fit_intercept' : [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('polynomialfeatures', PolynomialFeatures(degree=4, include_bias=True, interaction_only=False)), ('ridge', Ridge(alpha=1e-10, copy_X=True, fit_intercept=False, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'ridge__fit_intercept': [True, False], 'ridge__alpha': array([  1.00000e-10,   1.14895e-10, ...,   8.70359e+01,   1.00000e+02])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(mean_squared_error, greater_is_better=False),\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(model, parameters, scoring  = MSE_scorer)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ridge__alpha': 100.0, 'ridge__fit_intercept': False}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.2860065796831401"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMAE : 0.40617534457399895\n",
      "\tMSE : 0.28122007679619443\n",
      "Coefficients: [ 0.01402577 -0.53098219 -0.07400098 -0.23966959  0.09713533 -0.14580423\n",
      " -0.05874485 -0.10293873 -0.20274901  0.02504322 -0.06618392 -0.02339492\n",
      "  0.01626803  0.00109481 -0.0039772   0.02450044  0.03623887  0.01900384\n",
      " -0.01795561  0.01497264 -0.01428318 -0.02654292 -0.00623068  0.17179469\n",
      "  0.03320447  0.12803598  0.12441658 -0.05801291  0.02215548 -0.01095692\n",
      "  0.10991441  0.01027629  0.09097102 -0.22255764 -0.02012984 -0.08397818\n",
      " -0.07062734  0.00556453 -0.03801983 -0.04066627 -0.01187393  0.02800106\n",
      " -0.05403435 -0.0352311  -0.00375485 -0.04903981 -0.05786279  0.0166257\n",
      "  0.00202902 -0.1222086   0.00792277 -0.08137062  0.06765013 -0.0710553\n",
      "  0.05341563 -0.07433736 -0.00168079  0.00401451 -0.00774028 -0.00522434\n",
      " -0.09901494 -0.1255813   0.04569208  0.00854252  0.02377103 -0.01565349\n",
      " -0.01400153 -0.07317833  0.01700277 -0.00268709  0.06655094 -0.00995639\n",
      " -0.0651548   0.10251245 -0.06556746 -0.09421357 -0.06351702 -0.00535183\n",
      " -0.0641489   0.00284626 -0.04335142 -0.15262679 -0.03163096 -0.14908548\n",
      " -0.03670122 -0.01182411 -0.00868896 -0.01782457  0.00414327 -0.02490545\n",
      "  0.03831716  0.06081832  0.0309289   0.03911132 -0.01621249 -0.03760747\n",
      "  0.053531    0.00498758  0.00823446 -0.00368719 -0.02457384 -0.01362415\n",
      " -0.00992792  0.00623431 -0.02529759  0.00997735  0.0062321   0.01912225\n",
      " -0.03238123  0.00306901  0.01484834  0.01700844 -0.00452278 -0.0146815\n",
      "  0.0129269   0.00344077  0.00376038  0.00929157 -0.00289532 -0.04019897\n",
      " -0.02725971  0.00339883  0.02591221 -0.01575254 -0.00688109  0.01867695]\n",
      "Intercept: 0.0\n"
     ]
    }
   ],
   "source": [
    "# передаем лучший estimator, подобранный с помощью GridSearchCV\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "MAE_list = []\n",
    "MSE_list = []\n",
    "new_model = clf.best_estimator_\n",
    "\n",
    "for train_indexes, test_indexes in kf.split(X,y):\n",
    "    # X_train, y_train - данные, соответствующие обучающей выборке\n",
    "    X_train = X[train_indexes]\n",
    "    y_train = y[train_indexes]\n",
    "    \n",
    "    # X_test, y_test - данные, соответствующие тренировочной выборке\n",
    "    X_test = X[test_indexes]\n",
    "    y_test = y[test_indexes]\n",
    "    \n",
    "    new_model.fit(X_train, y_train) # Обучение на тестовых данных\n",
    "    y_predict = new_model.predict(X_test)\n",
    "        \n",
    "    current_mae = mean_absolute_error(y_test, y_predict)\n",
    "    current_mse = mean_squared_error(y_test, y_predict)\n",
    "        \n",
    "    MAE_list.append(current_mae)\n",
    "    MSE_list.append(current_mse)\n",
    "    \n",
    "print(\"\\tMAE : {0}\".format(np.mean(MAE_list)))\n",
    "print(\"\\tMSE : {0}\".format(np.mean(MSE_list)))    \n",
    "\n",
    "print(\"Coefficients: {0}\".format((new_model.get_params()['ridge']).coef_))\n",
    "print(\"Intercept: {0}\".format((new_model.get_params()['ridge']).intercept_ ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Для данной задачи мы выбрали значение альфа, подобранное Ridge регрессией, равное 100.0**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
